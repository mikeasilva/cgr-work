{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 211 Counts Scrapper\n",
    "\n",
    "This notebook scrapes the content of [211 Counts Dashboard](https://ny.211counts.org/) and stores the data in a SQLite database.  This scrapper should be able to process the data from any state with minimal alteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T20:13:28.861257Z",
     "start_time": "2020-06-08T20:13:28.215070Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta, date\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "\n",
    "# The name of the database file\n",
    "database_name = \"211_counts_data.db\"\n",
    "\n",
    "# The start and end date to scrape\n",
    "start_date = date(2014, 8, 1)\n",
    "end_date = date(2020, 6, 8)\n",
    "\n",
    "# The geographies\n",
    "geos = {\n",
    "    \"36001\": {'the_id': '{\"ids\":[\"463\"]}', 'type_code': 'C'},\n",
    "    \"36003\": {'the_id': '{\"ids\":[\"256\"]}', 'type_code': 'C'},\n",
    "    \"36007\": {'the_id': '{\"ids\":[\"268\"]}', 'type_code': 'C'},\n",
    "    \"36009\": {'the_id': '{\"ids\":[\"247\"]}', 'type_code': 'C'},\n",
    "    \"36011\": {'the_id': '{\"ids\":[\"278\"]}', 'type_code': 'C'},\n",
    "    \"36013\": {'the_id': '{\"ids\":[\"248\"]}', 'type_code': 'C'},\n",
    "    \"36015\": {'the_id': '{\"ids\":[\"258\"]}', 'type_code': 'C'},\n",
    "    \"36017\": {'the_id': '{\"ids\":[\"269\"]}', 'type_code': 'C'},\n",
    "    \"36019\": {'the_id': '{\"ids\":[\"453\"]}', 'type_code': 'C'},\n",
    "    \"36021\": {'the_id': '{\"ids\":[\"474\"]}', 'type_code': 'C'},\n",
    "    \"36023\": {'the_id': '{\"ids\":[\"284\"]}', 'type_code': 'C'},\n",
    "    \"36025\": {'the_id': '{\"ids\":[\"270\"]}', 'type_code': 'C'},\n",
    "    \"36027\": {'the_id': '{\"ids\":[\"461\"]}', 'type_code': 'C'},\n",
    "    \"36029\": {'the_id': '{\"ids\":[\"249\"]}', 'type_code': 'C'},\n",
    "    \"36031\": {'the_id': '{\"ids\":[\"452\"]}', 'type_code': 'C'},\n",
    "    \"36033\": {'the_id': '{\"ids\":[\"451\"]}', 'type_code': 'C'},\n",
    "    \"36035\": {'the_id': '{\"ids\":[\"473\"]}', 'type_code': 'C'},\n",
    "    \"36037\": {'the_id': '{\"ids\":[\"250\"]}', 'type_code': 'C'},\n",
    "    \"36039\": {'the_id': '{\"ids\":[\"472\"]}', 'type_code': 'C'},\n",
    "    \"36041\": {'the_id': '{\"ids\":[\"471\"]}', 'type_code': 'C'},\n",
    "    \"36043\": {'the_id': '{\"ids\":[\"265\"]}', 'type_code': 'C'},\n",
    "    \"36045\": {'the_id': '{\"ids\":[\"287\"]}', 'type_code': 'C'},\n",
    "    \"36049\": {'the_id': '{\"ids\":[\"288\"]}', 'type_code': 'C'},\n",
    "    \"36051\": {'the_id': '{\"ids\":[\"279\"]}', 'type_code': 'C'}, \n",
    "    \"36053\": {'the_id': '{\"ids\":[\"266\"]}', 'type_code': 'C'},\n",
    "    \"36055\": {'the_id': '{\"ids\":[\"280\"]}', 'type_code': 'C'},\n",
    "    \"36057\": {'the_id': '{\"ids\":[\"470\"]}', 'type_code': 'C'},\n",
    "    \"36059\": {'the_id': '{\"ids\":[\"447\"]}', 'type_code': 'C'},\n",
    "    \"36063\": {'the_id': '{\"ids\":[\"253\"]}', 'type_code': 'C'},\n",
    "    \"36065\": {'the_id': '{\"ids\":[\"267\"]}', 'type_code': 'C'},\n",
    "    \"36067\": {'the_id': '{\"ids\":[\"291\"]}', 'type_code': 'C'},\n",
    "    \"36069\": {'the_id': '{\"ids\":[\"281\"]}', 'type_code': 'C'},\n",
    "    \"36071\": {'the_id': '{\"ids\":[\"460\"]}', 'type_code': 'C'},\n",
    "    \"36073\": {'the_id': '{\"ids\":[\"254\"]}', 'type_code': 'C'},\n",
    "    \"36075\": {'the_id': '{\"ids\":[\"292\"]}', 'type_code': 'C'},\n",
    "    \"36077\": {'the_id': '{\"ids\":[\"273\"]}', 'type_code': 'C'},\n",
    "    \"36079\": {'the_id': '{\"ids\":[\"459\"]}', 'type_code': 'C'},\n",
    "    \"36083\": {'the_id': '{\"ids\":[\"469\"]}', 'type_code': 'C'},\n",
    "    \"36087\": {'the_id': '{\"ids\":[\"458\"]}', 'type_code': 'C'},\n",
    "    \"36089\": {'the_id': '{\"ids\":[\"293\"]}', 'type_code': 'C'},\n",
    "    \"36091\": {'the_id': '{\"ids\":[\"468\"]}', 'type_code': 'C'},\n",
    "    \"36093\": {'the_id': '{\"ids\":[\"467\"]}', 'type_code': 'C'},\n",
    "    \"36095\": {'the_id': '{\"ids\":[\"466\"]}', 'type_code': 'C'},\n",
    "    \"36097\": {'the_id': '{\"ids\":[\"259\"]}', 'type_code': 'C'},\n",
    "    \"36099\": {'the_id': '{\"ids\":[\"282\"]}', 'type_code': 'C'},\n",
    "    \"36101\": {'the_id': '{\"ids\":[\"260\"]}', 'type_code': 'C'},\n",
    "    \"36103\": {'the_id': '{\"ids\":[\"475\"]}', 'type_code': 'C'},\n",
    "    \"36105\": {'the_id': '{\"ids\":[\"457\"]}', 'type_code': 'C'},\n",
    "    \"36107\": {'the_id': '{\"ids\":[\"275\"]}', 'type_code': 'C'},\n",
    "    \"36109\": {'the_id': '{\"ids\":[\"285\"]}', 'type_code': 'C'},\n",
    "    \"36111\": {'the_id': '{\"ids\":[\"456\"]}', 'type_code': 'C'},\n",
    "    \"36113\": {'the_id': '{\"ids\":[\"465\"]}', 'type_code': 'C'},\n",
    "    \"36115\": {'the_id': '{\"ids\":[\"464\"]}', 'type_code': 'C'},\n",
    "    \"36117\": {'the_id': '{\"ids\":[\"283\"]}', 'type_code': 'C'},\n",
    "    \"36119\": {'the_id': '{\"ids\":[\"455\"]}', 'type_code': 'C'},\n",
    "    \"36121\": {'the_id': '{\"ids\":[\"255\"]}', 'type_code': 'C'},\n",
    "    \"36123\": {'the_id': '{\"ids\":[\"262\"]}', 'type_code': 'C'},\n",
    "}\n",
    "\n",
    "# Set to true if you want to initialize the database\n",
    "initialize_db = True\n",
    "\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Creates a range of dates (similar to the python range function)\n",
    "    \n",
    "    Parameters:\n",
    "        start_date (datetime.date): The date to start from\n",
    "        end_date (datetime.date): The date to end at\n",
    "    \n",
    "    Returns:\n",
    "        Generator output (datetime.date): The next date in the range\n",
    "    \"\"\"\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "        \n",
    "        \n",
    "def extract_data(el):\n",
    "    \"\"\"\n",
    "    Extracts data from 211 scrapped HTML content.\n",
    "\n",
    "    Parameters:\n",
    "        el (bs4.element.Tag): BeautifulSoup HTML element\n",
    "\n",
    "    Returns:\n",
    "        data_id (int): The id of the category\n",
    "        category (str): Description of the 2-1-1 call category\n",
    "        percentage (float): The percent of phone calls in this category\n",
    "        count (int): The count of phone calls of this category\n",
    "    \"\"\"\n",
    "    category = el.find(\"span\", {\"class\": \"toolTipSubCategory\"}).text\n",
    "    data_id = int(el[\"data-id\"])\n",
    "    data = el.find(\"span\", {\"class\": \"value\"})\n",
    "    percentage = float(data[\"data-percentage\"].strip(\"%\")) / 100\n",
    "    count = int(data[\"data-value\"])\n",
    "    return (data_id, category, percentage, count)\n",
    "\n",
    "\n",
    "def get_211_date(the_date):\n",
    "    \"\"\"\n",
    "    Produces the date in a form the 2-1-1 scraper needs.\n",
    "\n",
    "    Parameters:\n",
    "        the_date (datetime.date): The date to convert\n",
    "\n",
    "    Returns:\n",
    "        the_211_date (str): The date in 2-1-1 scrapper format\n",
    "    \"\"\"\n",
    "    months = {\n",
    "        1: \"Jan\",\n",
    "        2: \"Feb\",\n",
    "        3: \"Mar\",\n",
    "        4: \"Apr\",\n",
    "        5: \"May\",\n",
    "        6: \"Jun\",\n",
    "        7: \"Jul\",\n",
    "        8: \"Aug\",\n",
    "        9: \"Sep\",\n",
    "        10: \"Oct\",\n",
    "        11: \"Nov\",\n",
    "        12: \"Dec\",\n",
    "    }\n",
    "    the_211_date = (\n",
    "        months[the_date.month] + \" \" + str(the_date.day) + \", \" + str(the_date.year)\n",
    "    )\n",
    "    return the_211_date\n",
    "\n",
    "\n",
    "def process_211_lifeline_html(geo, html, the_date):\n",
    "    \"\"\"\n",
    "    Parses the html, extracts data, and returns a pandas dataframe\n",
    "    \n",
    "    Parameters:\n",
    "        geo (str): CGR Geography ID\n",
    "        html (str): HTML content\n",
    "        the_date (str): The date of the HTML content\n",
    "    \n",
    "    Returns:\n",
    "        df (pandas.DataFrame): Data frame of total counts and percentages by category\n",
    "    \"\"\"\n",
    "    data = list()\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "    # Get the top level categories\n",
    "    for div in soup.findAll(\"div\", {\"class\": \"categoriesDiv\"}):\n",
    "        for el in div.findAll(\"div\", {\"class\": \"categories\"}):\n",
    "            try:\n",
    "                data_id, category, percentage, count = extract_data(el)\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"category_id\": data_id,\n",
    "                        \"parent_category_id\": None,\n",
    "                        \"category\": category,\n",
    "                        \"percentage\": percentage,\n",
    "                        \"count\": count,\n",
    "                    }\n",
    "                )\n",
    "            except:\n",
    "                continue\n",
    "    # Get the sub categories\n",
    "    for div in soup.findAll(\"div\", {\"class\": \"subcategoriesDiv\"}):\n",
    "        for ul in div.findAll(\"ul\", {\"class\": \"details\"}):\n",
    "            parent = int(ul[\"id\"].split(\"-\")[1])\n",
    "            for el in ul.findAll(\"div\", {\"class\": \"categories\"}):\n",
    "                try:\n",
    "                    data_id, category, percentage, count = extract_data(el)\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"category_id\": data_id,\n",
    "                            \"parent_category_id\": parent,\n",
    "                            \"category\": category,\n",
    "                            \"percentage\": percentage,\n",
    "                            \"count\": count,\n",
    "                        }\n",
    "                    )\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"date\"] = the_date\n",
    "    df[\"geography_id\"] = geo\n",
    "    return(df)\n",
    "\n",
    "def scrape_and_save_211_count_data(the_id, the_type_code, the_date, datetime_date, geo_id, db):\n",
    "    \"\"\"\n",
    "    Scrapes 211 Count content, extracts the data, and saves it to a database\n",
    "    \n",
    "    Parameters:\n",
    "        the_id (str): 211 ID for the geography\n",
    "        the_type_code (str): 211 type code for the geography\n",
    "        the_date (str): 211 formated date\n",
    "        datetime_date (datetime.date): The date in datetime format\n",
    "        geo_id (str): The internal geography id\n",
    "        db (sqlalchemy.engine.base.Engine): The SQL Alchemy engine\n",
    "    \"\"\"\n",
    "    \n",
    "    cookies = {\n",
    "        '_ga': 'GA1.2.1786037618.1591293165',\n",
    "        '_gid': 'GA1.2.2065705029.1591626272',\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Connection': 'keep-alive',\n",
    "        'Accept': 'text/html, */*; q=0.01',\n",
    "        'X-Requested-With': 'XMLHttpRequest',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
    "        'Origin': 'https://ny.211counts.org',\n",
    "        'Sec-Fetch-Site': 'same-origin',\n",
    "        'Sec-Fetch-Mode': 'cors',\n",
    "        'Sec-Fetch-Dest': 'empty',\n",
    "        'Referer': 'https://ny.211counts.org/',\n",
    "        'Accept-Language': 'en-US,en;q=0.9,fr;q=0.8',\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "      'identifierCategory': '',\n",
    "      'sourceType': '',\n",
    "      'fromMobile': 'false',\n",
    "      'id': the_id,\n",
    "      'timeIntervalId': '0',\n",
    "      'centerId': '22',\n",
    "      'fromDate': the_date,\n",
    "      'toDate': the_date,\n",
    "      'type': the_type_code\n",
    "    }\n",
    "    # Request the data\n",
    "    response = requests.post('https://ny.211counts.org/dashBoard/barChart', headers=headers, cookies=cookies, data=data)\n",
    "    # Process the response\n",
    "    df = process_211_lifeline_html(geo_id, response.text, datetime_date)\n",
    "    # Save the processed data\n",
    "    df.to_sql(\"totals\", db, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T20:13:29.037686Z",
     "start_time": "2020-06-08T20:13:28.863234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DB\n",
    "if initialize_db:\n",
    "    import os\n",
    "    if os.path.exists(database_name):\n",
    "        os.unlink(database_name)\n",
    "    con = sqlite3.connect(database_name)\n",
    "    cur = con.cursor()\n",
    "    cur.execute('''CREATE TABLE \"totals\" (\n",
    "        \"category_id\" BIGINT,\n",
    "        \"parent_category_id\" BIGINT DEFAULT NULL,\n",
    "        \"category\" TEXT,\n",
    "        \"percentage\" FLOAT,\n",
    "        \"count\" BIGINT,\n",
    "        \"date\" TEXT,\n",
    "        \"geography_id\" TEXT\n",
    "    );''')\n",
    "    cur.execute('''CREATE INDEX \"ix_totals_index\" ON \"totals\" (\"category_id\", \"category\", \"parent_category_id\", \"date\", \"geography_id\");''')\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-08T20:13:28.216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2014-08-01\n",
      "Getting data for 2014-08-02\n",
      "Getting data for 2014-08-03\n",
      "Getting data for 2014-08-04\n",
      "Getting data for 2014-08-05\n",
      "Getting data for 2014-08-06\n",
      "Getting data for 2014-08-07\n",
      "Getting data for 2014-08-08\n",
      "Getting data for 2014-08-09\n",
      "Getting data for 2014-08-10\n",
      "Getting data for 2014-08-11\n",
      "Getting data for 2014-08-12\n",
      "Getting data for 2014-08-13\n"
     ]
    }
   ],
   "source": [
    "db = create_engine(\"sqlite:///\" + database_name)\n",
    "\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    print(\"Getting data for \" + str(single_date))\n",
    "    for geo_id, g in geos.items():\n",
    "        the_id = g[\"the_id\"]\n",
    "        the_type_code = g[\"type_code\"]\n",
    "        the_date = get_211_date(single_date)\n",
    "        scrape_and_save_211_count_data(the_id, the_type_code, the_date, single_date, geo_id, db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
